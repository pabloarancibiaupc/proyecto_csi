{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b53d66fa-ac6f-4370-8595-f58312ed9119",
   "metadata": {},
   "source": [
    "# Proyecto CSI: predecir la palabra root de una oración\n",
    "Autores: Oriol Catasús Llena, Pablo Arancibia Barahona\n",
    "\n",
    "Fecha 14 de enero de 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e38aefbf-975b-473b-ab6e-714f74186acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import csv\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b711eb3-49f9-4eb3-b71f-f6e103fefaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PUD = './pud26/English-all.heads'\n",
    "LAL_FILE_PATH = './output_file.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80094b32-53fb-4961-8207-51951d82c1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para obtener los datos de archivos PUD\n",
    "def get_data(path):\n",
    "    f = open(path, \"r\")\n",
    "    data = []\n",
    "    \n",
    "    for x in f:\n",
    "        data += [[int(y) for y in x.split(' ')]]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4322e4c1-f5c9-4092-8a9a-64662ed29b26",
   "metadata": {},
   "source": [
    "# Libreria LAL\n",
    "Primero miramos si el conjunto de arboles es correcto. Luego procesamos el conjunto de arboles y generamos un fichero CSV con sus métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e946d8c1-b0d3-4045-8c8d-a82cfe8da56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lal\n",
    "\n",
    "def process_treebank(path, lal_file_path):\n",
    "    errlist = lal.io.check_correctness_treebank(path)\n",
    "    for err in errlist:\n",
    "        print(err)\n",
    "    err = lal.io.process_treebank(path, lal_file_path)\n",
    "    if err:\n",
    "        print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cc4a7f0-1e5f-4e12-b8e5-8c8fb4324f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "process_treebank(PATH_PUD, LAL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b83917e-3642-4dd4-878e-7963fbd57608",
   "metadata": {},
   "source": [
    "En caso de contar con un archivo de metricas producto de LAL, estas se cargan para su posterior uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d3e1dec-dda1-477e-a342-4bcb414a39ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_from_lal(lal_file_path):\n",
    "    metrics = []\n",
    "    with open(lal_file_path, 'r') as file:\n",
    "        csv_reader = csv.DictReader(file, delimiter='\\t')\n",
    "        for row in csv_reader:\n",
    "            metrics.append(row)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ea16410-153c-45f9-baeb-00355bebe00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_distancias(grafo):\n",
    "    n = len(grafo)\n",
    "    distancias = [[float('inf')] * n for _ in range(n)]\n",
    "\n",
    "    # Inicializar las distancias conocidas\n",
    "    for i in range(n):\n",
    "        distancias[i][i] = 0\n",
    "        vecino = grafo[i]\n",
    "        if vecino != 0:\n",
    "            distancias[i][vecino - 1] = 1  # Peso siempre es 1\n",
    "            distancias[vecino - 1][i] = 1  # Asegurar bidireccionalidad\n",
    "\n",
    "    # Calcular las distancias mínimas\n",
    "    for k in range(n):\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                distancias[i][j] = min(distancias[i][j], distancias[i][k] + distancias[k][j])\n",
    "\n",
    "    return [sum(d)/n for d in distancias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e170413b-f868-4737-921b-46a09e65f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(data, metrics):\n",
    "    dataframe_dict = {\n",
    "        'vertex_degree': [],\n",
    "        'vertex_distance': [],\n",
    "        'centre': [],\n",
    "        'centroid': [],\n",
    "        'class': [],\n",
    "    }\n",
    "    \n",
    "    for sentence, m in zip(data, metrics):\n",
    "        dataframe_dict['class'] += [1 if word == 0 else 0 for word in sentence]\n",
    "        dataframe_dict['centre'] += [1 if int(m['tree_centre1']) == i or int(m['tree_centre2']) == i else 0 for i in range(len(sentence))]\n",
    "        dataframe_dict['centroid'] += [1 if int(m['tree_centroid1']) == i or int(m['tree_centroid2']) == i else 0 for i in range(len(sentence))]\n",
    "        dataframe_dict['vertex_degree'] += [sentence.count(index + 1) for index in range(len(sentence))]\n",
    "        dataframe_dict['vertex_distance'] += calcular_distancias(sentence)\n",
    "\n",
    "    return pd.DataFrame(dataframe_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd55a9d8-91a0-4060-8dbc-0b396c787bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(dataframe):\n",
    "    scaler = MinMaxScaler()\n",
    "    dataframe_normalized = scaler.fit_transform(dataframe)\n",
    "    dataframe_normalized = pd.DataFrame(dataframe_normalized, columns=dataframe.columns)\n",
    "    dataframe_normalized['centre'] = dataframe_normalized['centre'].astype(int)\n",
    "    dataframe_normalized['centroid'] = dataframe_normalized['centroid'].astype(int)\n",
    "    dataframe_normalized['class'] = dataframe_normalized['class'].astype(int)\n",
    "\n",
    "    return dataframe_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82de0d85-89f4-450e-8c21-dd6d7e6a5b7d",
   "metadata": {},
   "source": [
    "# Creación de la matriz\n",
    "Haciendo uso de las funciones anteriores se crea un matriz normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48b1290e-5c96-43c3-acf3-2439dbd4646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(PATH_PUD)\n",
    "metrics = get_metrics_from_lal(LAL_FILE_PATH)\n",
    "dataframe = create_matrix(data, metrics)\n",
    "dataframe_normalized = normalize_data(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95c1e213-4c5d-4407-b5e0-e12a42220907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 16, 4, 2, 6, 7, 4, 10, 10, 7, 16, 16, 16, 15, 16, 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vertex_degree</th>\n",
       "      <th>vertex_distance</th>\n",
       "      <th>centre</th>\n",
       "      <th>centroid</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375931</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.339913</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.565022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.565022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.565022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.438961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375931</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.249870</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.348918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.438961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.438961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.312900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.429957</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.222857</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.348918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.258874</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.357922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384935</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vertex_degree  vertex_distance  centre  centroid  class\n",
       "0        0.000000         0.375931       0         0      0\n",
       "1        0.111111         0.339913       0         0      0\n",
       "2        0.000000         0.565022       0         0      0\n",
       "3        0.000000         0.565022       0         0      0\n",
       "4        0.000000         0.565022       0         0      0\n",
       "5        0.333333         0.438961       0         0      0\n",
       "6        0.000000         0.375931       0         0      0\n",
       "7        0.444444         0.249870       1         0      0\n",
       "8        0.000000         0.474978       0         0      0\n",
       "9        0.000000         0.474978       0         0      0\n",
       "10       0.000000         0.474978       0         0      0\n",
       "11       0.333333         0.348918       0         0      0\n",
       "12       0.000000         0.438961       0         0      0\n",
       "13       0.000000         0.438961       0         0      0\n",
       "14       0.333333         0.312900       0         0      0\n",
       "15       0.000000         0.556017       0         0      0\n",
       "16       0.111111         0.429957       0         0      0\n",
       "17       0.444444         0.222857       1         1      1\n",
       "18       0.000000         0.348918       0         0      0\n",
       "19       0.000000         0.474978       0         0      0\n",
       "20       0.000000         0.474978       0         0      0\n",
       "21       0.444444         0.348918       0         0      0\n",
       "22       0.000000         0.474978       0         0      0\n",
       "23       0.000000         0.474978       0         0      0\n",
       "24       0.333333         0.258874       0         0      0\n",
       "25       0.000000         0.483983       0         0      0\n",
       "26       0.000000         0.483983       0         0      0\n",
       "27       0.000000         0.483983       0         0      0\n",
       "28       0.333333         0.357922       0         0      0\n",
       "29       0.000000         0.384935       0         0      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview de los datos\n",
    "print(data[1])\n",
    "dataframe_normalized.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea57e096-7024-4a17-adff-302315dc80f1",
   "metadata": {},
   "source": [
    "# Balanceo de clases de la matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b07407c6-754c-456a-9582-43025f7bb810",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_normalized_balanced = dataframe_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4e4856-3c76-43a9-9cc0-508655de310c",
   "metadata": {},
   "source": [
    "# Creación de pipeline de entrenamiento\n",
    "Se crea una clase de evaluación de multiples modelos para una mejor escalabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67f65657-3d06-4b5c-9f2b-4397cc326ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def division(numerador, denominador, valor_predeterminado=0):\n",
    "    resultado = valor_predeterminado if denominador == 0 else numerador / denominador\n",
    "    return resultado\n",
    "\n",
    "class EvaluateModel:\n",
    "\n",
    "    def __init__(self, models, verbose = 0):\n",
    "        self._models = list(models.values())\n",
    "        self._model_names = list(models.keys())\n",
    "        self._verbose = verbose\n",
    "\n",
    "    def _fit_cross_validation(self, model, X, y, num_folds=5):\n",
    "        cv_scores = cross_validate(\n",
    "            model,\n",
    "            X,\n",
    "            y,\n",
    "            cv=num_folds,\n",
    "            scoring=('accuracy', 'precision', 'recall', 'f1'),\n",
    "        )\n",
    "        model_fit = model.fit(X, y)\n",
    "\n",
    "        return model_fit, cv_scores\n",
    "\n",
    "    def _evaluate_with_dataframe(self, model, dataframe, target_column = 'class', iterations = 10):\n",
    "        accuracies = []\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        fscores = []\n",
    "\n",
    "        for x in range(iterations):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                dataframe.loc[:, dataframe.columns != target_column],\n",
    "                dataframe[target_column]\n",
    "            )\n",
    "            y_test = y_test.values.astype(int)\n",
    "\n",
    "            model_fit, cv_scores = self._fit_cross_validation(model, X_train, y_train)\n",
    "            predictions = model_fit.predict(X_test)\n",
    "\n",
    "            cm = confusion_matrix(y_test, predictions)\n",
    "            accuracy, precision, recall, fscore = self.get_metrics(cm)\n",
    "    \n",
    "            if self._verbose == 1:\n",
    "                print(f'Metrics Iteration {x}')\n",
    "                print(confusion_matrix(y_test, predictions))\n",
    "                print(f\"Accuracy = {accuracy}; Precision = {precision}; Recall = {recall}; fscore = {fscore}\\n\")\n",
    "    \n",
    "            accuracies.append(accuracy)\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            fscores.append(fscore)\n",
    "\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        mean_precision = np.mean(precisions)\n",
    "        mean_recall = np.mean(recalls)\n",
    "        mean_fscore = np.mean(fscores)\n",
    "        \n",
    "        print('Average')\n",
    "        print(f\"Accuracy = {mean_accuracy}; Precision = {mean_precision}; Recall = {mean_recall}; fscore = {mean_fscore}\\n\")\n",
    "\n",
    "        return mean_accuracy, mean_precision, mean_recall, mean_fscore\n",
    "\n",
    "    def _accuracy_custom(self, TN, FP, FN, TP):\n",
    "        return division((TP + TN),(TP + TN + FP + FN))\n",
    "    \n",
    "    def _recall_custom(self, TN, FP, FN, TP):\n",
    "        return division((TP),(TP + FN))\n",
    "    \n",
    "    def _precision_custom(self, TN, FP, FN, TP):\n",
    "        return division((TP),(TP + FP))\n",
    "    \n",
    "    def _fscore_custom(self, recall_metric, precision_metric):\n",
    "        return division(2, division(1, recall_metric) + (division(1, precision_metric)))\n",
    "\n",
    "    def get_metrics(self, confusion_matrix):\n",
    "        TN, FP, FN, TP = confusion_matrix.ravel()\n",
    "        \n",
    "        accuracy_metric = self._accuracy_custom(TN, FP, FN, TP)\n",
    "        precision_metric = self._precision_custom(TN, FP, FN, TP)\n",
    "        recall_metric = self._recall_custom(TN, FP, FN, TP)\n",
    "        fscore_metric = self._fscore_custom(recall_metric, precision_metric)\n",
    "        \n",
    "        return accuracy_metric, precision_metric, recall_metric, fscore_metric\n",
    "        \n",
    "    def evaluate_models_with_dataframe(self, dataframe, target_column = 'class', iterations = 10):\n",
    "        for i, model in enumerate(self._models):\n",
    "            print(f'######### {self._model_names[i]} #########')\n",
    "            self._evaluate_with_dataframe(model, dataframe, target_column, iterations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e71ef-7722-41b4-bb0b-3b1dc8b636ab",
   "metadata": {},
   "source": [
    "# Evaluación de los modelos con datos NO balanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ff478f6-ee44-486c-868f-d761a1086bc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DummyClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOGISTIC REGRESION\u001b[39m\u001b[38;5;124m'\u001b[39m: LogisticRegression(C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e5\u001b[39m, solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m, multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultinomial\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMOST FREQUEST CLASS\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mDummyClassifier\u001b[49m(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmost_frequent\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRANDOM CLASS\u001b[39m\u001b[38;5;124m'\u001b[39m: DummyClassifier(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      7\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m EvaluateModel(models, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      8\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mevaluate_models_with_dataframe(dataframe_normalized)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DummyClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'LOGISTIC REGRESION': LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial'),\n",
    "    'MOST FREQUEST CLASS': DummyClassifier(strategy='most_frequent'),\n",
    "    'RANDOM CLASS': DummyClassifier(strategy='uniform'),\n",
    "}\n",
    "\n",
    "evaluator = EvaluateModel(models, verbose = 0)\n",
    "evaluator.evaluate_models_with_dataframe(dataframe_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178c1d2b-0977-406e-baae-1294ca6e03a9",
   "metadata": {},
   "source": [
    "# Evaluación de los modelos con datos balanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af6b926-dce9-4967-b1aa-ba5bb3ac0f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate_models_with_dataframe(dataframe_normalized_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805d463e-6729-4c27-af3d-250f9331e7ff",
   "metadata": {},
   "source": [
    "# Conclusiones generales preliminares\n",
    "1. bla\n",
    "2. bla bla"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:csi]",
   "language": "python",
   "name": "conda-env-csi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
